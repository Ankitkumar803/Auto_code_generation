{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook reads openssl .c source code and generates new source code\n",
    "#### References\n",
    "##### https://www.tensorflow.org/tutorials/sequences/recurrent\n",
    "##### https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "### Prerequisites install tensorflow and keras\n",
    "#### pip install tensorflow\n",
    "#### pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "#### read all files and concatenate into a single file train.txt\n",
    "#### Add tags \"<start\"> and \"< eof >\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWD=C:\\Users\\user\\Desktop\\experiments\n",
      "readSize=73702\n"
     ]
    }
   ],
   "source": [
    "PWD=os.getcwd()\n",
    "print(\"PWD=\" + str(PWD))\n",
    "train_filename = PWD+\"./train.txt\"\n",
    "\n",
    "readSize = 0\n",
    "\n",
    "if (os.path.isfile(train_filename)):\n",
    "    os.remove(train_filename)\n",
    "    \n",
    "# read every 3rd file otherwise getting out of memory errors\n",
    "i = 0\n",
    "with open(train_filename, \"w\") as a:\n",
    "    for path, subdirs, files in os.walk(PWD+\"/openssl-master\"):\n",
    "        for filename in files:\n",
    "            if (filename.endswith(\".c\") and (i%3 == 0)):\n",
    "                #print(\"Reading \"+ filename)\n",
    "                f = os.path.join(path, filename)\n",
    "                readSize += os.path.getsize(f)\n",
    "                currfile = open(f).read()\n",
    "                a.write(\"<start>\")\n",
    "                a.write(currfile)\n",
    "                a.write(\"<eof>\")\n",
    "                i=i+1\n",
    "                \n",
    "print(\"readSize=\"+str(readSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open \"train.txt\" convert into lower case and sort them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 73714\n",
      "Total Vocab length (unique chars in input) : 67\n"
     ]
    }
   ],
   "source": [
    "raw_text = open(train_filename).read().lower()\n",
    "INPUT_FILE_LEN = len(raw_text)\n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "VOCAB_LENGTH = len(chars)\n",
    "\n",
    "print (\"Length of file: \"+ str(INPUT_FILE_LEN))\n",
    "print (\"Total Vocab length (unique chars in input) : \"+ str(VOCAB_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create mapping of unique chars to integers, and a reverse mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '<': 28, '=': 29, '>': 30, '?': 31, '[': 32, '\\\\': 33, ']': 34, '^': 35, '_': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'w': 59, 'x': 60, 'y': 61, 'z': 62, '{': 63, '|': 64, '}': 65, '~': 66}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '<', 29: '=', 30: '>', 31: '?', 32: '[', 33: '\\\\', 34: ']', 35: '^', 36: '_', 37: 'a', 38: 'b', 39: 'c', 40: 'd', 41: 'e', 42: 'f', 43: 'g', 44: 'h', 45: 'i', 46: 'j', 47: 'k', 48: 'l', 49: 'm', 50: 'n', 51: 'o', 52: 'p', 53: 'q', 54: 'r', 55: 's', 56: 't', 57: 'u', 58: 'v', 59: 'w', 60: 'x', 61: 'y', 62: 'z', 63: '{', 64: '|', 65: '}', 66: '~'}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_to_int)\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 73614\n",
      "X.shape=(73614, 100, 1)\n",
      "y.shape=(73614, 67)\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, INPUT_FILE_LEN - SEQ_LENGTH, 1):\n",
    "    seq_in = raw_text[i:i + SEQ_LENGTH]\n",
    "    seq_out = raw_text[i + SEQ_LENGTH]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "samples = len(dataX)\n",
    "print( \"Total samples: \"+ str(samples))\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (samples, SEQ_LENGTH, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(VOCAB_LENGTH)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "print(\"X.shape=\" + str(X.shape))\n",
    "print(\"y.shape=\" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model with 2 LSTM Layers with dropout 0.2, 1 Dense layer with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2)) # 0.5\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 67)                17219     \n",
      "=================================================================\n",
      "Total params: 806,723\n",
      "Trainable params: 806,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "73614/73614 [==============================] - 193s 3ms/step - loss: 2.9715\n",
      "Epoch 2/10\n",
      "73614/73614 [==============================] - 193s 3ms/step - loss: 2.6835\n",
      "Epoch 3/10\n",
      "73614/73614 [==============================] - 196s 3ms/step - loss: 2.4470\n",
      "Epoch 4/10\n",
      "73614/73614 [==============================] - 197s 3ms/step - loss: 2.2116\n",
      "Epoch 5/10\n",
      "73614/73614 [==============================] - 195s 3ms/step - loss: 2.0355\n",
      "Epoch 6/10\n",
      "73614/73614 [==============================] - 194s 3ms/step - loss: 1.8932\n",
      "Epoch 7/10\n",
      "73614/73614 [==============================] - 194s 3ms/step - loss: 1.7874\n",
      "Epoch 8/10\n",
      "73614/73614 [==============================] - 198s 3ms/step - loss: 1.6939\n",
      "Epoch 9/10\n",
      "73614/73614 [==============================] - 195s 3ms/step - loss: 1.6186\n",
      "Epoch 10/10\n",
      "73614/73614 [==============================] - 195s 3ms/step - loss: 1.5495\n"
     ]
    }
   ],
   "source": [
    "histroy = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# list all data in history\n",
    "print(histroy.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(histroy.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input code starts with: [ ut, db->db);\n",
      "    bio_free(out);\n",
      "    if (j <= 0)\n",
      "        goto err;\n",
      "\n",
      "    out = bio_new_file(buf[1], \"w ]\n",
      "\");\n",
      "    if (reenem)\n",
      "        return 0;\n",
      "    return ret;\n",
      "}\n",
      "\n",
      "ent set_ser_cdrt(const char *frl,\n",
      "innst char *arg,\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "#####.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"input code starts with: [\", ''.join([int_to_char[value] for value in pattern]), \"]\")\n",
    "# generate characters\n",
    "for i in range(500):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(VOCAB_LENGTH)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\n#####.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
